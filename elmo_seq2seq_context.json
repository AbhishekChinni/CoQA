{
  "dataset_reader": {
    "type": "coqa_seq2seq_reader",
    "lazy": true,
    "token_indexers": {
      "tokens": {
	      "type": "single_id",
	      "lowercase_tokens": true
      },  
      "elmo": {
	      "type": "elmo_characters"
      },  
      "token_characters": {
	      "type": "characters",
	      "character_tokenizer": {
		      "byte_encoding": "utf-8",
		      "start_tokens": [
			      259 
		      ],  
		      "end_tokens": [
			      260 
		      ]   
	      }   
      }   
    }
  },
  "train_data_path": "https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json",
  "validation_data_path": "https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json",
  "model": {
    "type": "seq2seq_model",
    "source_embedder": {
      "token_embedders": {
        "tokens": {
          "type": "embedding",
          "pretrained_file": "https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz",
          "embedding_dim": 100,
	  "trainable": false
	},
	"elmo": {
		"type": "elmo_token_embedder",
		"options_file": "https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json",
		"weight_file": "https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5",
		"do_layer_norm": false,
		"dropout": 0.5 
	},  
	"token_characters": {
		"type": "character_encoding",
		"embedding": {
			"num_embeddings": 262,
			"embedding_dim": 16
		},  
		"encoder": {
			"type": "cnn",
			"embedding_dim": 16, 
			"num_filters": 100,
			"ngram_filter_sizes": [
				5   
			]   
		},  
		"dropout": 0.2 
	}
      }
    },
    "max_decoding_steps": 20,
    "beam_size":3,
    "encoder": {
      "type": "lstm",
      "bidirectional": true,
      "input_size": 1224,
      "hidden_size": 200,
      "num_layers": 1,
      "dropout": 0.2
    },
    "attention_function": {
      "type": "linear",
      "combination": "x,y,x*y",
      "tensor_1_dim": 400,
      "tensor_2_dim": 400
    }
  },
  "iterator": {
    "type": "bucket",
    "batch_size": 32,
    "max_instances_in_memory": 5000,
    "sorting_keys": [
      [
        "source_tokens",
        "num_tokens"
      ]
    ]
  },
  "trainer": {
    "cuda_device":-1,
    "learning_rate_scheduler": {
      "type": "reduce_on_plateau",
      "factor": 0.5,
      "mode": "max",
      "patience": 3
    },
    "num_epochs": 30,
    "optimizer": {
      "type": "sgd",
      "lr": 0.05,
      "momentum": 0.9
    },
	"model_save_interval": 10,
    "patience": 10,
    "validation_metric": "+f1"
  }
}
